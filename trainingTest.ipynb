{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Setup Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available on your system! Using MPS.\n",
      "Tensor is on device: mps:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check for CUDA, MPS, or fallback to CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU:\", torch.cuda.get_device_name(0))\n",
    "    \n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS is available on your system! Using MPS.\")\n",
    "    \n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Neither CUDA nor MPS is available. Using CPU.\")\n",
    "\n",
    "# Example tensor on the selected device\n",
    "tensor = torch.ones((2, 2), device=device)\n",
    "print(f\"Tensor is on device: {tensor.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.datasetup import AmazonDatasetSetup\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading config file at src/data/datasetConfigAmazon.json\n",
      "Dataset Config set as:\n",
      "{'category': 'Industrial_and_Scientific',\n",
      " 'urls': {'interactionDataUrl': 'https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_2023/benchmark/5core/rating_only/',\n",
      "          'metaDataUrl': 'https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_2023/raw/meta_categories/',\n",
      "          'reviewDataUrl': 'https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_2023/raw/review_categories/'},\n",
      " 'filterCriteria': {'requiredFields': {'parent_asin': True,\n",
      "                                       'description': True,\n",
      "                                       'images': True,\n",
      "                                       'title': True,\n",
      "                                       'average_rating': False,\n",
      "                                       'features': False,\n",
      "                                       'price': False,\n",
      "                                       'details': False},\n",
      "                    'filterItemsBasedOnFeatures': True,\n",
      "                    'filterkInteractions': 5}}\n",
      "Dataset already downloaded and preprocessed, no further action from DatasetSetup object.\n",
      "Number of users in dataset: (12839, 7212)\n"
     ]
    }
   ],
   "source": [
    "# Industrial\n",
    "root=\"data/AmazonReviews\"\n",
    "os.makedirs(root, exist_ok=True)\n",
    "datasetConfig = \"src/data/datasetConfigAmazon.json\"\n",
    "datasetName = \"AmazonIndustrialDataset\"\n",
    "\n",
    "AmazonIndustrialDataset = AmazonDatasetSetup(root, datasetConfig, datasetName, devCtrl=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.graphDatasets import AmazonGraphDataset\n",
    "from src.data.utils import binarizeEdgesByThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_threshold = 3  #@param {type: \"integer\"}: Ratings equal to or greater than 3 are positive items.\n",
    "\n",
    "config_dict = {\n",
    "    \"num_samples_per_user\": 10, # default are 500\n",
    "    \"num_users\": 12839, # default are 200\n",
    "\n",
    "    \"epochs\": 10, # 100\n",
    "    \"batch_size\": 128,\n",
    "    \"lr\": 0.001,\n",
    "    \"weight_decay\": 0.1,\n",
    "\n",
    "    \"embedding_size\": 64,\n",
    "    \"num_layers\": 5,\n",
    "    \"K\": 10,\n",
    "    \"mf_rank\": 8,\n",
    "\n",
    "    \"minibatch_per_print\": 100,\n",
    "    \"epochs_per_print\": 1,\n",
    "\n",
    "    \"val_frac\": 0.2,\n",
    "    \"test_frac\": 0.1,\n",
    "\n",
    "    \"model_name\": \"model.pth\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazonIndustrialDataset = AmazonGraphDataset(\n",
    "    datasetSetup = AmazonIndustrialDataset,\n",
    "    config_dict = config_dict,\n",
    "    rating_threshold = rating_threshold,\n",
    "    transform=binarizeEdgesByThreshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_amazon_Industrial_and_Scientific.pt'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazonIndustrialDataset.processed_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mamazonIndustrialDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Uni/Masterthesis/MLLM_RecSys/src/data/graphDatasets.py:67\u001b[0m, in \u001b[0;36mAmazonGraphDataset.process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# initialize the adjacency matrix\u001b[39;00m\n\u001b[1;32m     65\u001b[0m rat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_user, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_item)\n\u001b[0;32m---> 67\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mratings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrating\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnum_users\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-geometric/lib/python3.12/site-packages/pandas/core/frame.py:1554\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1552\u001b[0m using_cow \u001b[38;5;241m=\u001b[39m using_copy_on_write()\n\u001b[1;32m   1553\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m-> 1554\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block:\n\u001b[1;32m   1556\u001b[0m         s\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39madd_references(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-geometric/lib/python3.12/site-packages/pandas/core/series.py:487\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_mgr:\n\u001b[1;32m    479\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    481\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis deprecated and will raise in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    484\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    485\u001b[0m         )\n\u001b[0;32m--> 487\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[43mibase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_extract_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m     index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-geometric/lib/python3.12/site-packages/pandas/core/indexes/base.py:7688\u001b[0m, in \u001b[0;36mmaybe_extract_name\u001b[0;34m(name, obj, cls)\u001b[0m\n\u001b[1;32m   7684\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   7685\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo not recognize join method \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7688\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmaybe_extract_name\u001b[39m(name, obj, \u001b[38;5;28mcls\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Hashable:\n\u001b[1;32m   7689\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   7690\u001b[0m \u001b[38;5;124;03m    If no name is passed, then extract it from data, validating hashability.\u001b[39;00m\n\u001b[1;32m   7691\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   7692\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (Index, ABCSeries)):\n\u001b[1;32m   7693\u001b[0m         \u001b[38;5;66;03m# Note we don't just check for \"name\" attribute since that would\u001b[39;00m\n\u001b[1;32m   7694\u001b[0m         \u001b[38;5;66;03m#  pick up e.g. dtype.name\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "amazonIndustrialDataset.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timthiele/Documents/Uni/Masterthesis/MLLM_RecSys/src/data/graphDatasets.py:118: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(os.path.join(self.processed_dir, f\"data_amazon_{self.datasetSetup.category}.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Users: 12839\n",
      "#Items: 7212\n"
     ]
    }
   ],
   "source": [
    "data = amazonIndustrialDataset.get()\n",
    "\n",
    "train_mask, val_mask, test_mask = \\\n",
    "        amazonIndustrialDataset.train_val_test_split(val_frac=config_dict[\"val_frac\"],\n",
    "                                       test_frac=config_dict[\"test_frac\"])\n",
    "\n",
    "n_users = len(pd.Series(data[\"users\"]).unique())\n",
    "m_items = len(pd.Series(data[\"items\"]).unique())\n",
    "print(f\"#Users: {n_users}\")\n",
    "print(f\"#Items: {m_items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following\n",
    "- https://medium.com/stanford-cs224w/lightgcn-for-movie-recommendation-eb6d112f1e8\n",
    "- https://colab.research.google.com/drive/1VfP6JlWbX_AJnx88yN1tM3BYE6XAADiy?usp=sharing#scrollTo=IaZK6fwHzyd_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import os.path as osp\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "import random\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 10\n",
    "from sklearn import metrics\n",
    "from tensorly import decomposition\n",
    "\n",
    "from torch.functional import tensordot\n",
    "from torch import nn, optim, Tensor\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset, Data, download_url, extract_zip\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.typing import Adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch has version 2.4.1.post3\n",
      "Torch version: 2.4.1.post3\n",
      "Cuda available: False\n",
      "Torch geometric version: 2.6.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch has version {torch.__version__}\")\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "print(f\"Torch geometric version: {torch_geometric.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCNConv(MessagePassing):\n",
    "    r\"\"\"The neighbor aggregation operator from the `\"LightGCN: Simplifying and\n",
    "    Powering Graph Convolution Network for Recommendation\"\n",
    "    <https://arxiv.org/abs/2002.02126#>`_ paper\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Size of each input sample, or :obj:`-1` to derive\n",
    "            the size from the first input(s) to the forward method.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        num_users (int): Number of users for recommendation.\n",
    "        num_items (int): Number of items to recommend.\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int,\n",
    "                 num_users: int, num_items: int, **kwargs):\n",
    "        super(LightGCNConv, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        pass  # There are no layer parameters to learn.\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Adj) -> Tensor:\n",
    "        \"\"\"Performs neighborhood aggregation for user/item embeddings.\"\"\"\n",
    "        user_item = \\\n",
    "                torch.zeros(self.num_users, self.num_items, device=x.device)\n",
    "        user_item[edge_index[:, 0], edge_index[:, 1]] = 1\n",
    "        user_neighbor_counts = torch.sum(user_item, axis=1)\n",
    "        item_neightbor_counts = torch.sum(user_item, axis=0)\n",
    "        # Compute weight for aggregation: 1 / sqrt(N_u * N_i)\n",
    "        weights = user_item / torch.sqrt(\n",
    "                user_neighbor_counts.repeat(self.num_items, 1).T \\\n",
    "                * item_neightbor_counts.repeat(self.num_users, 1))\n",
    "        weights = torch.nan_to_num(weights, nan=0)\n",
    "        out = torch.concat((weights.T @ x[:self.num_users],\n",
    "                            weights @ x[self.num_users:]), 0)\n",
    "        return out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
    "                                   self.out_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 config: dict,\n",
    "                 device=None,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_users  = config[\"n_users\"]\n",
    "        self.num_items  = config[\"m_items\"]\n",
    "        self.embedding_size = config[\"embedding_size\"]\n",
    "        self.in_channels = self.embedding_size\n",
    "        self.out_channels = self.embedding_size\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "\n",
    "        # 0-th layer embedding.\n",
    "        self.embedding_user_item = torch.nn.Embedding(\n",
    "            num_embeddings=self.num_users + self.num_items,\n",
    "            embedding_dim=self.embedding_size)\n",
    "        self.alpha = None\n",
    "\n",
    "        # random normal init seems to be a better choice when lightGCN actually\n",
    "        # don't use any non-linear activation function\n",
    "        nn.init.normal_(self.embedding_user_item.weight, std=0.1)\n",
    "        print('use NORMAL distribution initilizer')\n",
    "\n",
    "        self.f = nn.Sigmoid()\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(LightGCNConv(\n",
    "                self.embedding_size, self.embedding_size,\n",
    "                num_users=self.num_users, num_items=self.num_items, **kwargs))\n",
    "\n",
    "        for _ in range(1, self.num_layers):\n",
    "            self.convs.append(\n",
    "                LightGCNConv(\n",
    "                        self.embedding_size, self.embedding_size,\n",
    "                        num_users=self.num_users, num_items=self.num_items,\n",
    "                        **kwargs))\n",
    "\n",
    "        self.device = None\n",
    "        if device is not None:\n",
    "            self.convs.to(device)\n",
    "            self.device = device\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Adj, *args, **kwargs) -> Tensor:\n",
    "        xs: List[Tensor] = []\n",
    "\n",
    "        edge_index = torch.nonzero(edge_index)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index, *args, **kwargs)\n",
    "            if self.device is not None:\n",
    "                x = x.to(self.device)\n",
    "            xs.append(x)\n",
    "        xs = torch.stack(xs)\n",
    "\n",
    "        self.alpha = 1 / (1 + self.num_layers) * torch.ones(xs.shape)\n",
    "        if self.device is not None:\n",
    "            self.alpha = self.alpha.to(self.device)\n",
    "            xs = xs.to(self.device)\n",
    "        x = (xs * self.alpha).sum(dim=0)  # Sum along K layers.\n",
    "        return x\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, num_layers={self.num_layers})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "\n",
    "def getUsersRating(model, users, data):\n",
    "    \"\"\" Get the embedding of users\n",
    "    INPUT:\n",
    "        model: the LightGCN model you are training on\n",
    "        users: this is the user index (note: use 0-indexed and not user number,\n",
    "            which is 1-indexed)\n",
    "        data: the entire data, used to fetch all users and all items\n",
    "    \"\"\"\n",
    "    all_users_items = model(model.embedding_user_item.weight.clone(),\n",
    "                            data[\"edge_index\"])\n",
    "    all_users = all_users_items[:len(data[\"users\"])]\n",
    "    items_emb = all_users_items[len(data[\"users\"]):]\n",
    "    users_emb = all_users[users.long()]\n",
    "    rating = model.f(torch.matmul(users_emb, items_emb.t()))\n",
    "    return rating\n",
    "\n",
    "def getEmbedding(model, users, pos, neg, data, mask):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "        model: the LightGCN model you are training on\n",
    "        users: this is the user index (note: use 0-indexed and not user number,\n",
    "            which is 1-indexed)\n",
    "        pos: positive index corresponding to an item that the user like\n",
    "        neg: negative index corresponding to an item that the user doesn't like\n",
    "        data: the entire data, used to fetch all users and all items\n",
    "        mask: Masking matrix indicating edges present in the current\n",
    "            train / validation / test set.\n",
    "    \"\"\"\n",
    "    # assuming we always search for users and items by their indices (instead of\n",
    "    # user/item number)\n",
    "    all_users_items = model(model.embedding_user_item.weight.clone(),\n",
    "                            data[\"edge_index\"] * mask)\n",
    "    all_users = all_users_items[:len(data[\"users\"])]\n",
    "    all_items = all_users_items[len(data[\"users\"]):]\n",
    "    users_emb = all_users[users]\n",
    "    pos_emb = all_items[pos]\n",
    "    neg_emb = all_items[neg]\n",
    "    n_user = len(data[\"users\"])\n",
    "    users_emb_ego = model.embedding_user_item(users)\n",
    "    # offset the index to fetch embedding from user_item\n",
    "    pos_emb_ego = model.embedding_user_item(pos + n_user)\n",
    "    neg_emb_ego = model.embedding_user_item(neg + n_user)\n",
    "    return users_emb, pos_emb, neg_emb, users_emb_ego, pos_emb_ego, neg_emb_ego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses\n",
    "def bpr_loss(model, users, pos, neg, data, mask):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "        model: the LightGCN model you are training on\n",
    "        users: this is the user index (note: use 0-indexed and not user number,\n",
    "            which is 1-indexed)\n",
    "        pos: positive index corresponding to an item that the user like\n",
    "            (0-indexed, note to index items starting from 0)\n",
    "        neg: negative index corresponding to an item that the user doesn't like\n",
    "        data: the entire data, used to fetch all users and all items\n",
    "        mask: Masking matrix indicating edges present in the current\n",
    "            train / validation / test set.\n",
    "    OUTPUT:\n",
    "        loss, reg_loss\n",
    "    \"\"\"\n",
    "    # assuming we always sample the same number of positive and negative sample\n",
    "    # per user\n",
    "    assert len(users) == len(pos) and len(users) == len(neg)\n",
    "    (users_emb, pos_emb, neg_emb,\n",
    "    userEmb0,  posEmb0, negEmb0) = getEmbedding(model, users.long(), pos.long(),\n",
    "                                                neg.long(), data, mask)\n",
    "    reg_loss = (1/2)*(userEmb0.norm(2).pow(2) +\n",
    "                        posEmb0.norm(2).pow(2)  +\n",
    "                        negEmb0.norm(2).pow(2))/float(len(users))\n",
    "    pos_scores = torch.mul(users_emb, pos_emb)\n",
    "    pos_scores = torch.sum(pos_scores, dim=1)\n",
    "    neg_scores = torch.mul(users_emb, neg_emb)\n",
    "    neg_scores = torch.sum(neg_scores, dim=1)\n",
    "\n",
    "    loss = torch.mean(torch.nn.functional.softplus(neg_scores - pos_scores))\n",
    "\n",
    "    return loss, reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "def personalized_topk(pred, K, user_indices, edge_index):\n",
    "    \"\"\"Computes TopK precision and recall.\n",
    "\n",
    "    Args:\n",
    "        pred: Predicted similarities between user and item.\n",
    "        K: Number of items to rank.\n",
    "        user_indices: Indices of users for each prediction in `pred`.\n",
    "        edge_index: User and item connection matrix.\n",
    "\n",
    "    Returns:\n",
    "        Average Top K precision and recall for users in `user_indices`.\n",
    "    \"\"\"\n",
    "    per_user_preds = collections.defaultdict(list)\n",
    "    for index, user in enumerate(user_indices):\n",
    "        per_user_preds[user.item()].append(pred[index].item())\n",
    "    precisions = 0.0\n",
    "    recalls = 0.0\n",
    "    for user, preds in per_user_preds.items():\n",
    "        while len(preds) < K:\n",
    "            preds.append(random.choice(range(edge_index.shape[1])))\n",
    "        top_ratings, top_items = torch.topk(torch.tensor(preds), K)\n",
    "        correct_preds = edge_index[user, top_items].sum().item()\n",
    "        total_pos = edge_index[user].sum().item()\n",
    "        precisions += correct_preds / K\n",
    "        recalls += correct_preds / total_pos if total_pos != 0 else 0\n",
    "    num_users = len(user_indices.unique())\n",
    "    return precisions / num_users, recalls / num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling\n",
    "def _sample_pos_neg(data, mask, num_samples_per_user):\n",
    "    \"\"\"Samples (user, positive item, negative item) tuples per user.\n",
    "\n",
    "    If a user does not have a postive (negative) item, we choose an item\n",
    "    with unknown liking (an item without raw rating data).\n",
    "\n",
    "    Args:\n",
    "        data: Dataset object containing edge_index and raw ratings matrix.\n",
    "        mask: Masking matrix indicating edges present in the current\n",
    "            train / validation / test set.\n",
    "        num_samples_per_user: Number of samples to generate for each user.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor object of (user, positive item, negative item) samples.\n",
    "    \"\"\"\n",
    "    print(\"=====Starting to sample=====\")\n",
    "    start = time.time()\n",
    "    samples = []\n",
    "    all_items = set(range(len(data[\"items\"])))\n",
    "    for user_index, user in enumerate(data[\"users\"]):\n",
    "        pos_items = set(\n",
    "            torch.nonzero(data[\"edge_index\"][user_index])[:, 0].tolist())\n",
    "        unknown_items = all_items.difference(\n",
    "                set(\n",
    "                    torch.nonzero(\n",
    "                        data[\"raw_edge_index\"][user_index])[:, 0].tolist()))\n",
    "        neg_items = all_items.difference(\n",
    "            set(pos_items)).difference(set(unknown_items))\n",
    "        unmasked_items = set(torch.nonzero(mask[user_index])[:, 0].tolist())\n",
    "        if len(unknown_items.union(pos_items)) == 0 or \\\n",
    "                len(unknown_items.union(neg_items)) == 0:\n",
    "            continue\n",
    "        for _ in range(num_samples_per_user):\n",
    "            if len(pos_items.intersection(unmasked_items)) == 0:\n",
    "                pos_item_index = random.choice(\n",
    "                    list(unknown_items.intersection(unmasked_items)))\n",
    "            else:\n",
    "                pos_item_index = random.choice(\n",
    "                    list(pos_items.intersection(unmasked_items)))\n",
    "            if len(neg_items.intersection(unmasked_items)) == 0:\n",
    "                neg_item_index = random.choice(\n",
    "                    list(unknown_items.intersection(unmasked_items)))\n",
    "            else:\n",
    "                neg_item_index = random.choice(\n",
    "                    list(neg_items.intersection(unmasked_items)))\n",
    "            samples.append((user_index, pos_item_index, neg_item_index))\n",
    "    end = time.time()\n",
    "    print(f\"=====Sampling completed (took {end - start} seconds)=====\")\n",
    "    return torch.tensor(samples, dtype=torch.int32)\n",
    "\n",
    "def sample_pos_neg(data, train_mask, val_mask, test_mask, num_samples_per_user):\n",
    "    \"\"\"Samples (user, positive item, negative item) tuples per user.\n",
    "\n",
    "    If a user does not have a postive (negative) item, we choose an item\n",
    "    with unknown liking (an item without raw rating data).\n",
    "\n",
    "    Args:\n",
    "        data: Dataset object containing edge_index and raw ratings matrix.\n",
    "        train_mask: Masking matrix indicating edges present in train set.\n",
    "        val_mask: Masking matrix indicating edges present in validation set.\n",
    "        test_mask: Masking matrix indicating edges present in test set.\n",
    "        num_samples_per_user: Number of samples to generate for each user.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor object of (user, positive item, negative item) samples for\n",
    "        train, validation and test.\n",
    "    \"\"\"\n",
    "    train_samples = _sample_pos_neg(data, train_mask, num_samples_per_user)\n",
    "    val_samples = _sample_pos_neg(data, val_mask, num_samples_per_user)\n",
    "    test_samples = _sample_pos_neg(data, test_mask, num_samples_per_user)\n",
    "    return train_samples, val_samples, test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use NORMAL distribution initilizer\n",
      "=====Starting to sample=====\n",
      "=====Sampling completed (took 21.32737398147583 seconds)=====\n",
      "=====Starting to sample=====\n",
      "=====Sampling completed (took 20.63888168334961 seconds)=====\n",
      "=====Starting to sample=====\n",
      "=====Sampling completed (took 19.526625871658325 seconds)=====\n",
      "#Training samples: 128390 #Validation samples: 128390 #Test samples: 128390\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Training on the 0 epoch\n",
      "Training on epoch 0 minibatch 1/1004 completed\n",
      " bpr_loss on current minibatch is 0.789753, and regularization loss is 0.096606.\n",
      " Top K precision = 0.0023622047244094492, recall = 0.003674540682414698.\n",
      "Training on epoch 0 minibatch 101/1004 completed\n",
      " bpr_loss on current minibatch is 0.771789, and regularization loss is 0.078642.\n",
      " Top K precision = 0.0015748031496062994, recall = 0.002559055118110236.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 67\u001b[0m\n\u001b[1;32m     64\u001b[0m loss_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     66\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 67\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminibatch_per_print\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     70\u001b[0m     all_users \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinspace(start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     71\u001b[0m                                end\u001b[38;5;241m=\u001b[39mn_users \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, steps\u001b[38;5;241m=\u001b[39mn_users)\u001b[38;5;241m.\u001b[39mlong()\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-geometric/lib/python3.12/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-geometric/lib/python3.12/site-packages/torch/optim/optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-geometric/lib/python3.12/site-packages/torch/optim/adam.py:226\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    214\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    216\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    217\u001b[0m         group,\n\u001b[1;32m    218\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    223\u001b[0m         state_steps,\n\u001b[1;32m    224\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-geometric/lib/python3.12/site-packages/torch/optim/optimizer.py:161\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-geometric/lib/python3.12/site-packages/torch/optim/adam.py:766\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 766\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-geometric/lib/python3.12/site-packages/torch/optim/adam.py:379\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    376\u001b[0m     param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(param)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_config = {\n",
    "    \"n_users\": n_users,\n",
    "    \"m_items\": m_items,\n",
    "    \"embedding_size\": config_dict[\"embedding_size\"],\n",
    "    \"num_layers\": config_dict[\"num_layers\"],\n",
    "}\n",
    "\n",
    "lightGCN = LightGCN(model_config, device=device)\n",
    "\n",
    "num_samples_per_user = config_dict[\"num_samples_per_user\"]\n",
    "epochs = config_dict[\"epochs\"]\n",
    "batch_size = config_dict[\"batch_size\"]\n",
    "lr = config_dict[\"lr\"]\n",
    "weight_decay = config_dict[\"weight_decay\"]\n",
    "\n",
    "K = config_dict[\"K\"]\n",
    "\n",
    "lightGCN.to(device)\n",
    "\n",
    "samples_train, samples_val, samples_test = \\\n",
    "        sample_pos_neg(data, train_mask, val_mask, test_mask,\n",
    "                       num_samples_per_user)\n",
    "\n",
    "samples_train=samples_train.to(device)\n",
    "samples_val=samples_val.to(device)\n",
    "samples_test=samples_test.to(device)\n",
    "train_mask=train_mask.to(device)\n",
    "val_mask=val_mask.to(device)\n",
    "test_mask=test_mask.to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "print(f\"#Training samples: {len(samples_train)}\",\n",
    "      f\"#Validation samples: {len(samples_val)}\",\n",
    "      f\"#Test samples: {len(samples_test)}\")\n",
    "\n",
    "optimizer = optim.Adam(lightGCN.parameters(), lr=lr)\n",
    "print(\"Optimizer:\", optimizer)\n",
    "\n",
    "epochs_tracked = []\n",
    "train_topks = []\n",
    "val_topks = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Training on the {} epoch\".format(epoch))\n",
    "    lightGCN.train()\n",
    "    loss_sum = 0\n",
    "    # Shuffle the order of rows.\n",
    "    samples_train = samples_train[torch.randperm(samples_train.size()[0])]\n",
    "    for batch_idx in range(math.ceil(len(samples_train) / batch_size)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        current_batch = \\\n",
    "            samples_train[batch_idx*batch_size: (batch_idx+1)*batch_size]\n",
    "        # Shuffle the order of rows.\n",
    "        current_batch = current_batch[torch.randperm(current_batch.size()[0])]\n",
    "        users = current_batch[:, 0:1]\n",
    "        pos = current_batch[:, 1:2]\n",
    "        neg = current_batch[:, 2:3]\n",
    "\n",
    "        loss, reg_loss = bpr_loss(lightGCN, users, pos, neg, data,\n",
    "                                  train_mask)\n",
    "        reg_loss = reg_loss * weight_decay\n",
    "        loss = loss + reg_loss\n",
    "        loss_sum += loss.detach()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % config_dict[\"minibatch_per_print\"] == 0:\n",
    "            all_users = torch.linspace(start=0,\n",
    "                                       end=n_users - 1, steps=n_users).long()\n",
    "            user_indices = current_batch[:, 0]\n",
    "            user_indices = user_indices.repeat(2).long()\n",
    "            item_indices = torch.cat(\n",
    "                (current_batch[:, 1], current_batch[:, 2])).long()\n",
    "            pred = getUsersRating(lightGCN,\n",
    "                                  all_users,\n",
    "                                  data)[user_indices, item_indices]\n",
    "            truth = data[\"edge_index\"][user_indices, item_indices]\n",
    "            topk_precision, topk_recall = \\\n",
    "                personalized_topk(pred, K, user_indices, data[\"edge_index\"])\n",
    "\n",
    "            print(\"Training on epoch {} minibatch {}/{} completed\\n\".format(epoch, batch_idx+1,\n",
    "                                                                            math.ceil(len(samples_train) / batch_size)),\n",
    "                  \"bpr_loss on current minibatch is {}, and regularization loss is {}.\\n\".format(round(float(loss.detach().cpu()), 6),\n",
    "                                                                                                 round(float(reg_loss.detach().cpu()), 6)),\n",
    "                  \"Top K precision = {}, recall = {}.\".format(topk_precision, topk_recall))\n",
    "\n",
    "    if epoch % config_dict[\"epochs_per_print\"] == 0:\n",
    "        epochs_tracked.append(epoch)\n",
    "\n",
    "        # evaluation on both the training and validation set\n",
    "        lightGCN.eval()\n",
    "        # predict on the training set\n",
    "        users = samples_train[:, 0:1]\n",
    "        user_indices = samples_train[:, 0]\n",
    "        user_indices = user_indices.repeat(2).long()\n",
    "        item_indices = torch.cat(\n",
    "            (samples_train[:, 1], samples_train[:, 2])).long()\n",
    "        pred = getUsersRating(lightGCN,\n",
    "                              users[:,0],\n",
    "                              data)[user_indices, item_indices]\n",
    "        truth = data[\"edge_index\"][users.long()[:,0]]\\\n",
    "            [user_indices, item_indices]\n",
    "        train_topk_precision, train_topk_recall = \\\n",
    "            personalized_topk(pred, K, user_indices, data[\"edge_index\"])\n",
    "        train_topks.append((train_topk_precision, train_topk_recall))\n",
    "\n",
    "        # predict on the validation set\n",
    "        users_val = samples_val[:, 0:1]\n",
    "        pos_val = samples_val[:, 1:2]\n",
    "        neg_val = samples_val[:, 2:3]\n",
    "\n",
    "        loss_val, reg_loss_val = bpr_loss(\n",
    "            lightGCN, users_val, pos_val, neg_val, data, val_mask)\n",
    "        reg_loss_val = reg_loss_val * weight_decay\n",
    "\n",
    "        # predict on the validation set\n",
    "        user_indices = samples_val[:, 0]\n",
    "        user_indices = user_indices.repeat(2).long()\n",
    "        item_indices = torch.cat((samples_val[:, 1], samples_val[:, 2])).long()\n",
    "        pred_val = getUsersRating(lightGCN,\n",
    "                                  users_val[:,0],\n",
    "                                  data)[user_indices, item_indices]\n",
    "        truth_val = data[\"edge_index\"][users_val.long()[:,0]]\\\n",
    "            [user_indices, item_indices]\n",
    "        val_topk_precision, val_topk_recall = \\\n",
    "            personalized_topk(pred_val, K, user_indices, data[\"edge_index\"])\n",
    "        val_topks.append((val_topk_precision, val_topk_recall))\n",
    "\n",
    "        print(\"\\nTraining on {} epoch completed.\\n\".format(epoch),\n",
    "              \"Average bpr_loss on train set is {} for the current epoch.\\n\".format(round(float(loss_sum/len(samples_train)), 6)),\n",
    "              \"Training top K precision = {}, recall = {}.\\n\".format(train_topk_precision, train_topk_recall),\n",
    "              \"Average bpr_loss on the validation set is {}, and regularization loss is {}.\\n\".format(round(float((loss_val+reg_loss_val)/len(samples_val)), 6),\n",
    "                                                                                                      round(float(reg_loss_val/len(samples_val)), 6)),\n",
    "              \"Validation top K precision = {}, recall = {}.\\n\".format(val_topk_precision, val_topk_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top k precision over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "\n",
    "plt.plot(epochs_tracked, [precision for precision, _ in train_topks],\n",
    "         label=\"Train\")\n",
    "plt.plot(epochs_tracked, [precision for precision, _ in val_topks],\n",
    "         label=\"Val\")\n",
    "plt.ylabel(f\"Top {K} precision\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top k recall over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs_tracked, [recall for _, recall in train_topks],\n",
    "         label=\"Train\")\n",
    "plt.plot(epochs_tracked, [recall for _, recall in val_topks],\n",
    "         label=\"Val\")\n",
    "plt.ylabel(f\"Top {K} recall\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "samples_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = amazonIndustrialDataset.get()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_test = samples_test[:, 0:1]\n",
    "pos_test = samples_test[:, 1:2]\n",
    "neg_test = samples_test[:, 2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_id = amazonIndustrialDataset.user_to_id \n",
    "item_to_id = amazonIndustrialDataset.item_to_id\n",
    "\n",
    "inverted_user_to_id = {v: k for k, v in user_to_id.items()}\n",
    "inverted_item_to_id = {v: k for k, v in item_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastUserInTestset = users_test[-1].item()\n",
    "inverted_user_to_id[lastUserInTestset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastItemInTestset = pos_test[-1].item()\n",
    "inverted_item_to_id[lastItemInTestset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predict on the test set\n",
    "lightGCN.eval()\n",
    "print(\"Training completed after {} epochs\".format(epochs))\n",
    "\n",
    "users_test = samples_test[:, 0:1]\n",
    "pos_test = samples_test[:, 1:2]\n",
    "neg_test = samples_test[:, 2:3]\n",
    "\n",
    "loss_test, reg_loss_test = bpr_loss(\n",
    "    lightGCN, users_test, pos_test, neg_test, data, test_mask)\n",
    "reg_loss_test = reg_loss_test * weight_decay\n",
    "\n",
    "# predict on the test set\n",
    "user_indices = samples_test[:, 0]\n",
    "user_indices = user_indices.repeat(2).long()\n",
    "item_indices = torch.cat((samples_test[:, 1], samples_test[:, 2])).long()\n",
    "pred_test = getUsersRating(lightGCN, users_test[:,0], data)\\\n",
    "    [user_indices, item_indices]\n",
    "truth_test = data[\"edge_index\"][users_test.long()[:,0]]\\\n",
    "    [user_indices, item_indices]\n",
    "test_topk_precision, test_topk_recall = personalized_topk(\n",
    "    pred_test, K, user_indices, data[\"edge_index\"])\n",
    "\n",
    "print(\"Average bpr_loss on the test set is {}, and regularization loss is {}.\\n\".format(round(float((loss_test+reg_loss_test)/len(samples_test)), 6),\n",
    "                                                                                                round(float(reg_loss_test/len(samples_test)), 6)),\n",
    "      \"Top K precision = {}, recall = {}.\".format(test_topk_precision, test_topk_recall))\n",
    "\n",
    "# Save model embeddings.\n",
    "torch.save(lightGCN, config_dict[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_emb, pos_emb, neg_emb, users_emb_ego, pos_emb_ego, neg_emb_ego = getEmbedding(\n",
    "    lightGCN, users_test, pos_test, neg_test, data, test_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sample pos neg function, we can do this simply after training\n",
    "# allows us to retrieve user and item representations\n",
    "\n",
    "pos_items = set(torch.nonzero(data[\"edge_index\"][user_index])[:, 0].tolist())\n",
    "unknown_items = all_items.difference(\n",
    "    set(\n",
    "        torch.nonzero(\n",
    "            data[\"raw_edge_index\"][user_index])[:, 0].tolist()))\n",
    "neg_items = all_items.difference(\n",
    "set(pos_items)).difference(set(unknown_items))\n",
    "\n",
    "\n",
    "# we can then create a dict with key and embedding for both\n",
    "# how would we do it for the neighbors of each node?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
