{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom CoLLM paper\\n\\nML-1M\\npreserve the interactions from the most recent twenty months, using the first 10 months for training, the middle 5 months for validation, and the last 5 months for testing\\nTrain: 33,891\\nValid: 10,401\\nTest: 7,331\\nUser: 839\\nItem: 3,256\\n\\n\\nAmazon-Book dataset\\npreserve interactions from the year 2017 (including about 4 million interactions)\\nallocating the first 11 months for training, and the remaining two half months for validation and testing, respectively\\n\\nfiltered out users and items with fewer than 20 interactions to ensure data quality for measuring warm-start performance\\n\\nTrain: 727,468\\nValid: 25,747\\nTest: 25,747\\nUser: 22,967\\nItem: 34,154\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from CoLLM paper\n",
    "\n",
    "ML-1M\n",
    "preserve the interactions from the most recent twenty months, using the first 10 months for training, the middle 5 months for validation, and the last 5 months for testing\n",
    "Train: 33,891\n",
    "Valid: 10,401\n",
    "Test: 7,331\n",
    "User: 839\n",
    "Item: 3,256\n",
    "\n",
    "\n",
    "Amazon-Book dataset\n",
    "preserve interactions from the year 2017 (including about 4 million interactions)\n",
    "allocating the first 11 months for training, and the remaining two half months for validation and testing, respectively\n",
    "\n",
    "filtered out users and items with fewer than 20 interactions to ensure data quality for measuring warm-start performance\n",
    "\n",
    "Train: 727,468\n",
    "Valid: 25,747\n",
    "Test: 25,747\n",
    "User: 22,967\n",
    "Item: 34,154\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timthiele/miniforge3/envs/pytorch-geometric/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "# from torch_geometric.data import Dataset, download_url\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from src.data.utils import loadFileFromURL\n",
    "from src.utils.wrapper import timeMeasured\n",
    "            \n",
    "\n",
    "class AmazonDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for the Amazon Review Dataset from 2023.\n",
    "    Overview: https://amazon-reviews-2023.github.io/main.html\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root, category=\"Books\", interactionDataUrl=None):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            root (str): root dir of dataset\n",
    "            category (str): category as e.g. 'Books'\n",
    "            interactionDataUrl (str): base url of the interaction data, default is: 5core and timestamp_w_his\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.category = category\n",
    "        self.interactionDataUrl = interactionDataUrl or \"https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_2023/benchmark/5core/timestamp_w_his\"\n",
    "        self.rawDataDir = Path(self.root) / \"raw\"\n",
    "        self.rawDataDir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.downloadInteractionData()\n",
    "        self.downloadItemData()\n",
    "    \n",
    "    @timeMeasured\n",
    "    def downloadInteractionData(self):\n",
    "        for split in [\"train\", \"valid\", \"test\"]:\n",
    "            datasetFilename = f\"{self.category}.{split}.csv.gz\"\n",
    "            datasetPath = self.rawDataDir / \"Interactions\" / datasetFilename\n",
    "            datasetPath.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            if not datasetPath.exists():\n",
    "                datasetUrl = f\"{self.interactionDataUrl}/{datasetFilename}\"\n",
    "                loadFileFromURL(datasetUrl, datasetPath)\n",
    "    \n",
    "    @timeMeasured\n",
    "    def downloadItemData(self):\n",
    "        datasetFilename = f\"{self.category}ItemMetadata.csv.gz\"\n",
    "        datasetPath = self.rawDataDir / \"Items\" / datasetFilename\n",
    "        datasetPath.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        if not datasetPath.exists():\n",
    "            try:\n",
    "                itemInformation = load_dataset(\n",
    "                    \"McAuley-Lab/Amazon-Reviews-2023\",\n",
    "                    f\"raw_meta_{self.category}\",\n",
    "                    split=\"full\",\n",
    "                    trust_remote_code=True\n",
    "                )\n",
    "                dataframe = pd.DataFrame.from_records(itemInformation)\n",
    "                dataframe.to_csv(datasetPath, index=False, compression=\"gzip\")\n",
    "                print(f\"File downloaded and saved to {datasetPath}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to download file. The following exception occured: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'root=\"data/Test\"\\nos.makedirs(root, exist_ok=True)\\ncategory = \"Books\"\\ninteractionDataUrl = \"https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_2023/benchmark/5core/timestamp_w_his\"\\n\\nAmazonDataset(root, category, interactionDataUrl)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''root=\"data/Test\"\n",
    "os.makedirs(root, exist_ok=True)\n",
    "category = \"Books\"\n",
    "interactionDataUrl = \"https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_2023/benchmark/5core/timestamp_w_his\"\n",
    "\n",
    "AmazonDataset(root, category, interactionDataUrl)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "import pprint\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "# from torch_geometric.data import Dataset, download_url\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from src.data.utils import loadFileFromURL\n",
    "from src.utils.wrapper import tryExcept, timeMeasured\n",
    "\n",
    "\n",
    "class AmazonDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for the Amazon Review Dataset from 2023.\n",
    "    Overview: https://amazon-reviews-2023.github.io/main.html\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root, datasetConfig, datasetName):\n",
    "        self.root = root\n",
    "        self.datasetConfig = datasetConfig\n",
    "        self.datasetName = datasetName\n",
    "        \n",
    "        with open(datasetConfig, \"r\") as configFile:\n",
    "            configData = json.load(configFile)\n",
    "            self.datasetConfig = configData.get(datasetName, {})\n",
    "            print(f\"Dataset Config set as:\")\n",
    "            pprint.pp(self.datasetConfig)\n",
    "        self.category = self.datasetConfig.get(\"category\")\n",
    "        urls = self.datasetConfig.get(\"urls\", {})\n",
    "        self.interactionDataUrl = urls.get(\"interactionDataUrl\", \"default_interaction_data_url\")\n",
    "        self.metaDataUrl = urls.get(\"metaDataUrl\", \"default_meta_data_url\")\n",
    "        self.reviewDataUrl = urls.get(\"reviewDataUrl\", \"default_review_data_url\")\n",
    "        \n",
    "        self.rawDataDir = Path(self.root) / \"raw\"\n",
    "        self.rawDataDir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.downloadInteractionData()\n",
    "        self.downloadItemDataAsJSON()\n",
    "        self.unwrapItemData(self.rawMetaDatasetPath)\n",
    "    \n",
    "    @tryExcept\n",
    "    @timeMeasured\n",
    "    def downloadInteractionData(self):\n",
    "        for split in [\"train\", \"valid\", \"test\"]:\n",
    "            datasetFilename = f\"{self.category}.{split}.csv.gz\"\n",
    "            datasetPath = self.rawDataDir / \"Interactions\" / datasetFilename\n",
    "            datasetPath.parent.mkdir(parents=True, exist_ok=True)\n",
    "            if not datasetPath.exists():\n",
    "                datasetUrl = urljoin(self.interactionDataUrl, datasetFilename)\n",
    "                loadFileFromURL(datasetUrl, datasetPath)\n",
    "    \n",
    "    @tryExcept\n",
    "    @timeMeasured\n",
    "    def downloadItemDataAsJSON(self):\n",
    "        metaDataFilename = f\"meta_{self.category}.jsonl.gz\"\n",
    "        self.rawMetaDatasetPath = self.rawDataDir / \"Items\" / metaDataFilename\n",
    "        self.rawMetaDatasetPath.parent.mkdir(parents=True, exist_ok=True)\n",
    "        if not self.rawMetaDatasetPath.exists():\n",
    "            loadFileFromURL(urljoin(self.metaDataUrl, metaDataFilename), self.rawMetaDatasetPath)\n",
    "        \n",
    "        reviewDataFilename = f\"{self.category}.jsonl.gz\"\n",
    "        self.rawReviewDatasetPath = self.rawDataDir / \"Items\" / reviewDataFilename\n",
    "        self.rawReviewDatasetPath.parent.mkdir(parents=True, exist_ok=True)\n",
    "        if not self.rawReviewDatasetPath.exists():\n",
    "            loadFileFromURL(urljoin(self.reviewDataUrl, reviewDataFilename), self.rawReviewDatasetPath)\n",
    "    \n",
    "    @tryExcept\n",
    "    @timeMeasured\n",
    "    def downloadItemDataFromHF(self):\n",
    "        datasetFilename = f\"{self.category}ItemMetadata.csv.gz\"\n",
    "        datasetPath = self.rawDataDir / \"Items\" / datasetFilename\n",
    "        datasetPath.parent.mkdir(parents=True, exist_ok=True)\n",
    "        if not datasetPath.exists():\n",
    "            itemInformation = load_dataset(\n",
    "                \"McAuley-Lab/Amazon-Reviews-2023\",\n",
    "                f\"raw_meta_{self.category}\",\n",
    "                split=\"full\",\n",
    "                trust_remote_code=True\n",
    "            )\n",
    "            dataframe = pd.DataFrame.from_records(itemInformation)\n",
    "            dataframe.to_csv(datasetPath, index=False, compression=\"gzip\")\n",
    "            print(f\"File downloaded and saved to {datasetPath}\")\n",
    "    \n",
    "    def checkRequiredFields(self, jsonLine):\n",
    "        \"\"\"\n",
    "        Checks whether the required fields are present based on the config.\n",
    "        Returns True if all required fields are valid; False otherwise.\n",
    "        \"\"\"\n",
    "        requiredFields = self.datasetConfig.get(\"required_fields\", {})\n",
    "        for field, isRequired in requiredFields.items():\n",
    "            if isRequired:\n",
    "                value = jsonLine.get(field)\n",
    "                # For description and images, we ensure they are non-empty lists\n",
    "                if field == \"description\" or field == \"images\":\n",
    "                    if not isinstance(value, list) or not value:\n",
    "                        return False\n",
    "                # For other fields, just check if they are truthy (non-null, non-empty)\n",
    "                elif not value:\n",
    "                    return False\n",
    "        return True\n",
    "    \n",
    "    @tryExcept\n",
    "    @timeMeasured\n",
    "    def unwrapItemData(self, datasetPath):\n",
    "        rawUnwrappedDataDir = self.rawDataDir / \"Items\" / \"Unwrapped\" / self.datasetName\n",
    "        os.makedirs(rawUnwrappedDataDir, exist_ok=True)\n",
    "        \n",
    "        with gzip.open(datasetPath, \"rt\", encoding=\"utf-8\") as f:\n",
    "            linesCount, self.dumpedJSONlist = 0, []\n",
    "            for line in f:\n",
    "                linesCount += 1\n",
    "                jsonLine = json.loads(line.strip())\n",
    "                if self.checkRequiredFields(jsonLine):  # Only save if required fields are valid\n",
    "                    parent_asin = jsonLine.get(\"parent_asin\")\n",
    "                    outputFilePath = rawUnwrappedDataDir / f\"{parent_asin}.json\"\n",
    "                    with open(outputFilePath, \"w\", encoding=\"utf-8\") as outputFile:\n",
    "                        json.dump(jsonLine, outputFile, indent=4)\n",
    "                    self.dumpedJSONlist.append(parent_asin)\n",
    "                if linesCount == 100:\n",
    "                    break\n",
    "        \n",
    "        print(f\"Unwrapped dataset from {datasetPath}\")\n",
    "        print(f\"Saved {len(self.dumpedJSONlist)} from a total of {linesCount} lines.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Config set as:\n",
      "{'category': 'All_Beauty',\n",
      " 'urls': {'interactionDataUrl': 'https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_2023/benchmark/5core/timestamp_w_his/',\n",
      "          'metaDataUrl': 'https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_2023/raw/meta_categories/',\n",
      "          'reviewDataUrl': 'https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_2023/raw/review_categories/'},\n",
      " 'required_fields': {'parent_asin': True,\n",
      "                     'description': True,\n",
      "                     'images': True,\n",
      "                     'title': True,\n",
      "                     'average_rating': False,\n",
      "                     'features': False,\n",
      "                     'price': False,\n",
      "                     'details': False}}\n",
      "downloadInteractionData executed in 0 hours, 0 minutes, 0 seconds.\n",
      "\n",
      "downloadItemDataAsJSON executed in 0 hours, 0 minutes, 0 seconds.\n",
      "\n",
      "Unwrapped dataset from data/Test/raw/Items/meta_All_Beauty.jsonl.gz\n",
      "Saved 29 from a total of 100 lines.\n",
      "unwrapItemData executed in 0 hours, 0 minutes, 0 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "root=\"data/Test\"\n",
    "os.makedirs(root, exist_ok=True)\n",
    "datasetConfig = \"src/data/datasetConfigAmazon.json\"\n",
    "datasetName = \"AmazonAllBeautyDataset\"\n",
    "\n",
    "AmazonBeautyDataset = AmazonDataset(root, datasetConfig, datasetName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
